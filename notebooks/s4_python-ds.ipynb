{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858f9f16-eb07-4ad2-97dd-04ddd9c53652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def make_random_nan(elements: np.ndarray,nan_count: int):\n",
    "    \"\"\"Creates Random NaN values\"\"\"\n",
    "    elements = elements.tolist()\n",
    "    element_length = len(elements)\n",
    "    if nan_count>element_length:\n",
    "        raise ValueError(\"NaN count cannot be greater than elements count\")\n",
    "    nan_indices = random.sample(range(element_length), nan_count)\n",
    "    for idx in nan_indices:\n",
    "        elements[idx] = np.nan\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ea6ca1-a1c9-4ca8-b219-db629223d452",
   "metadata": {},
   "source": [
    "##### Handeling Missing Data \n",
    "* df.dropna() → removes rows with missing values.\n",
    "* df.dropna(axis=1) → removes columns with missing values.\n",
    "* df.dropna(thresh=n) → keeps rows/columns with at least n non-null values.(axis=0 is row, axis=1 is col)\n",
    "\n",
    "#### Steps below:\n",
    "* Create a dummy data.\n",
    "* Play with those methods(handeling missing values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2ce2f-9dbf-4ee8-a72e-fe446fe035c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create random dummy features\n",
    "feature1 = make_random_nan(np.random.randint(0,10, 100),nan_count=10)\n",
    "feature2 = make_random_nan(np.random.randint(0,10, 100),nan_count=14)\n",
    "feature3 = make_random_nan(np.random.randint(0,10, 100),nan_count=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ea0966-1adb-4b80-a0e4-bd20df5e6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data = pd.DataFrame({\"f1\":feature1,\"f2\":feature2,\"f3\":feature3})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb24e35-212d-47dc-9d45-40dd0dfc2d0e",
   "metadata": {},
   "source": [
    "#### Play around with different methods for filling NaN values:\n",
    "#### Statstical filling:\n",
    "* ```df['col'].fillna(df['col'].mean())```    # mean imputation\n",
    "* ```df['col'].fillna(df['col'].median())```  # median imputation\n",
    "* ```df['col'].fillna(df['col'].mode()[0])``` # mode imputation\n",
    "\n",
    "#### Forward or Backward Filling:\n",
    "* ```df.fillna(method='ffill')```  # propagate previous value forward\n",
    "* ```df.fillna(method='bfill')```  # propagate next value backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9904b99-4da2-4a4b-b8b2-9e4153688aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_data[\"f3\"] = dummy_data[\"f3\"].fillna(dummy_data[\"f3\"].mean()) #fill f3 with its mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f7646-5194-4b31-8b15-c95ab0520bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f99c6-4d04-44b7-83eb-7af9ac8f22dc",
   "metadata": {},
   "source": [
    "#### Machine Learning:\n",
    "\n",
    "* Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d2bb40-4e09-480d-bb4e-979f03b20214",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocess\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#algorithm\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#metrics\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df = pd.read_csv(\"housing_price_dataset.csv\")\n",
    "\n",
    "X = pd.get_dummies(df.drop(columns=[\"Price\"]), drop_first=False)\n",
    "y = df[\"Price\"].values\n",
    "\n",
    "Xs = StandardScaler(with_mean=True).fit_transform(X)\n",
    "train_x, test_x, train_y, test_y = train_test_split(Xs,y,test_size=0.2)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "predictions = model.predict(test_x)\n",
    "\n",
    "print(f\"R2 score: {r2_score(test_y,predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9485da82-8ef1-41e5-8966-db41620c221f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toy problem to play with\n",
    "#given the muscle mass we predict athletcic performance\n",
    "\n",
    "muscle_mass          = [12,13,11,15,16,20,25,27]\n",
    "real_ath_performance = [3,4,5,6.4,7.2,7.9,9,12]\n",
    "\n",
    "pred_ath_performance = [3.5,2,4.8,6,6.8,7.5,10,11.7]\n",
    "\n",
    "var_ath =  np.mean(real_ath_performance)/len(real_ath_performance)\n",
    "var_fit =  (np.mean((np.array(real_ath_performance)-np.array(pred_ath_performance))**2))/len(real_ath_performance)\n",
    "r2_score_ = (var_ath-var_fit)/var_ath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3de31a-a281-4df0-889d-06cc58c9b1e9",
   "metadata": {},
   "source": [
    "##### Assignment:\n",
    "* Play with the above linear regression model by selecting different features and observe the metrics.\n",
    "* In the toy problem try to understand how r2 score is changing when you plug and play different values.\n",
    "* Write a function that takes a two list list as input arguments and computes r2 score.\n",
    "* Try understanding Grad Descent from your point of mathematical sense(optional)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
